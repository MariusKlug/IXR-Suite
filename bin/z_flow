#!/usr/bin/env python3
import argparse
import asyncio
import logging
import sys
import threading
import time
from abc import ABC, abstractmethod

import numpy as np
import pyqtgraph as pg
import scipy as sp
import scipy.signal
from brainflow.board_shim import BoardIds, BoardShim, BrainFlowInputParams, BrainFlowPresets
from brainflow.data_filter import (DataFilter, DetrendOperations, FilterTypes,
                                   WindowOperations)
from brainflow.exit_codes import *
from brainflow.ml_model import (BrainFlowClassifiers, BrainFlowMetrics,
                                BrainFlowModelParams, MLModel)
from pylsl import (StreamInfo, StreamInlet, StreamOutlet, local_clock,
                   resolve_byprop)
from pyqtgraph.Qt import QtCore, QtGui
from sklearn import svm
from sklearn.model_selection import cross_val_score

# f = open('test_board.log', 'w')
# sys.stdout = f
# print("test")
# f.close()


class Graph:
    def __init__(self, board_shim, calib_length, power_length, scale, offset, head_impact):
        pg.setConfigOption('background', '#264653')
        pg.setConfigOption('foreground', '#e9f5db')

        self.board_id = board_shim.get_board_id()
        self.board_shim = board_shim

        # print("\nEEG preset data format", BoardShim.get_board_descr(
        #     board_id=self.board_id, preset=BrainFlowPresets.DEFAULT_PRESET))
        # print("\nGyro/Aux preset data format",
        #       BoardShim.get_board_descr(board_id=self.board_id, preset=BrainFlowPresets.AUXILIARY_PRESET))
        # print("\nPPG/Anc preset data format", BoardShim.get_board_descr(board_id=self.board_id,
        #       preset=BrainFlowPresets.ANCILLARY_PRESET))

        self.eeg_channels = BoardShim.get_eeg_channels(self.board_id, BrainFlowPresets.DEFAULT_PRESET)
        self.gyro_channels = BoardShim.get_gyro_channels(self.board_id, BrainFlowPresets.AUXILIARY_PRESET)
        self.ppg_channels = BoardShim.get_ppg_channels(self.board_id, BrainFlowPresets.ANCILLARY_PRESET)
        self.eeg_sampling_rate = BoardShim.get_sampling_rate(self.board_id, BrainFlowPresets.DEFAULT_PRESET)
        self.gyro_sampling_rate = BoardShim.get_sampling_rate(self.board_id, BrainFlowPresets.AUXILIARY_PRESET)
        self.ppg_sampling_rate = BoardShim.get_sampling_rate(self.board_id, BrainFlowPresets.ANCILLARY_PRESET)
        self.update_speed_ms = 100
        self.window_size_plot = 7
        self.window_size_compute = 1.5
        self.num_points_plot = self.window_size_plot * self.eeg_sampling_rate
        self.num_points_compute = int(self.window_size_compute * self.eeg_sampling_rate)

        self.timestamp_old = 0

        # # brainflow ML module
        # MLModel.release_all()
        # concentration_params = BrainFlowModelParams(BrainFlowMetrics.CONCENTRATION.value, BrainFlowClassifiers.KNN.value)
        # self.concentration = MLModel(concentration_params)
        # self.concentration.prepare()
        # relaxation_params = BrainFlowModelParams(BrainFlowMetrics.RELAXATION.value, BrainFlowClassifiers.REGRESSION.value)
        # self.relaxation = MLModel(relaxation_params)
        # self.relaxation.prepare()

        # selfmade power metrics
        self.calib_length = int(calib_length * 1000 / self.update_speed_ms)
        self.hist_length = int(power_length * 1000 / self.update_speed_ms)
        self.brain_scale = scale
        self.brain_center = offset
        self.head_impact = head_impact

        self.inverse_workload_calib = [0, 1]
        self.inverse_workload_hist = [0, 1]
        self.inverse_workload = 0
        self.engagement_calib = [0, 1]
        self.engagement_hist = [0, 1]
        self.engagement = 0
        self.power_metrics = 0

        # LSL stream
        info_transmit = StreamInfo('BrainPower', 'Z-metric', 1, 0, 'float32', 'zflow_transmit_power')
        self.outlet_transmit = StreamOutlet(info_transmit)

        # start GUI
        self.app = QtGui.QApplication([])
        self.win = pg.GraphicsWindow(title='Z-flow', size=(1500, 1000))

        self._init_pens()
        self._init_timeseries()
        self._init_psd()
        self._init_band_plot()
        self._init_brain_power_plot()

        timer = QtCore.QTimer()
        timer.timeout.connect(self.update)
        timer.start(self.update_speed_ms)
        QtGui.QApplication.instance().exec_()

    def _init_pens(self):
        self.pens = list()
        self.brushes = list()
        colors = ['#e9c46a', '#f4a261', '#e76f51', '#d62828', '#2a9d8f', '#168aad', '#e9f5db', '#A57E2F', '#A53B2F']
        for i in range(len(colors)):
            pen = pg.mkPen({'color': colors[i], 'width': 2})
            self.pens.append(pen)
            brush = pg.mkBrush(colors[i])
            self.brushes.append(brush)

    def _init_timeseries(self):
        self.plots = list()
        self.curves = list()

        axeslabels_eeg = ['left ear', 'left front', 'right front', 'right ear']
        for i in range(len(self.eeg_channels)):
            p = self.win.addPlot(row=i, col=0)
            p.setMenuEnabled('left', False)
            p.showAxis('bottom', False)
            p.setMenuEnabled('bottom', False)
            p.setYRange(-150, 150, padding=0)
            p.showAxis('left', False)
            p.setTitle(axeslabels_eeg[i])
            self.plots.append(p)
            curve = p.plot(pen=self.pens[i % len(self.pens)])
            # curve.setDownsampling(auto=True, method='mean', ds=3)
            self.curves.append(curve)

        axeslabels_gyro = ['gyro 1', 'gyro 2', 'gyro 3']
        for i in range(len(self.gyro_channels)):
            p = self.win.addPlot(row=i + len(self.eeg_channels), col=0)
            p.setMenuEnabled('left', False)
            p.showAxis('bottom', False)
            p.setMenuEnabled('bottom', False)
            p.setYRange(-250, 250, padding=0)
            p.showAxis('left', False)
            p.setTitle(axeslabels_gyro[i])
            self.plots.append(p)
            curve = p.plot(pen=self.pens[i % len(self.pens)])
            # curve.setDownsampling(auto=True, method='mean', ds=3)
            self.curves.append(curve)

        axeslabels_ppg = ['heart']
        p = self.win.addPlot(row=1 + len(self.eeg_channels) + len(self.gyro_channels), col=0)
        p.setMenuEnabled('left', False)
        p.showAxis('bottom', False)
        p.setMenuEnabled('bottom', False)
        p.setYRange(-1500, 2000, padding=0)
        p.showAxis('left', False)
        p.setTitle(axeslabels_ppg[0])
        self.plots.append(p)
        curve = p.plot(pen=self.pens[3])
        # curve.setDownsampling(auto=True, method='mean', ds=3)
        self.curves.append(curve)

    def _init_psd(self):
        self.psd_plot = self.win.addPlot(row=0, col=1, rowspan=4)
        self.psd_plot.showAxis('left', False)
        self.psd_plot.setMenuEnabled('left', False)
        self.psd_plot.setTitle('spectral power')
        self.psd_plot.setLogMode(False, True)
        self.psd_plot.setLabel('bottom', 'frequency (Hz)')
        self.psd_plot.setXRange(0, 50, padding=0)
        self.psd_curves = list()
        self.psd_size = DataFilter.get_nearest_power_of_two(self.eeg_sampling_rate)
        for i in range(len(self.eeg_channels)):
            psd_curve = self.psd_plot.plot(pen=self.pens[i % len(self.pens)])
            psd_curve.setDownsampling(auto=True, method='mean', ds=3)
            self.psd_curves.append(psd_curve)

    def _init_band_plot(self):
        self.band_plot = self.win.addPlot(row=4, col=1, rowspan=2)
        self.band_plot.showAxis('left', False)
        self.band_plot.setMenuEnabled('left', False)
        self.band_plot.showAxis('bottom', True)
        self.band_plot.setMenuEnabled('bottom', False)
        self.band_plot.setTitle('EEG band powers')
        y = [0, 0, 0, 0, 0]
        x = [1, 2, 3, 4, 5]
        self.band_bar = pg.BarGraphItem(x=x, height=y, width=0.8, pen=self.pens[4], brush=self.brushes[4])
        self.band_plot.addItem(self.band_bar)
        self.band_plot.setXRange(0.1, 5.9, padding=0)
        self.band_plot.setYRange(-0.1, 50, padding=0)
        ticklabels = ['', 'delta', 'theta', 'alpha', 'beta', 'gamma']
        tickdict = dict(enumerate(ticklabels))
        ay = self.band_plot.getAxis('bottom')
        ay.setTicks([tickdict.items()])

    def _init_brain_power_plot(self):
        self.power_plot = self.win.addPlot(row=6, col=1, rowspan=3)
        self.power_plot.setTitle('final brain power')

        self.power_plot.showAxis('left', False)
        self.power_plot.setMenuEnabled('left', False)
        self.power_plot.showAxis('bottom', True)
        self.power_plot.setMenuEnabled('bottom', False)
        y = [0]
        x = [1]
        self.power_bar = pg.BarGraphItem(x=x, height=y, width=0.8, pen=self.pens[5], brush=self.brushes[5])
        self.power_plot.addItem(self.power_bar)
        self.power_plot.setXRange(0.1, 1.9, padding=0)
        self.power_plot.setYRange(-0.1, 1.1, padding=0)
        ticklabels = ['', '']
        tickdict = dict(enumerate(ticklabels))
        ay = self.power_plot.getAxis('bottom')
        ay.setTicks([tickdict.items()])

    def update(self):
        # collect EEG data
        eeg_data = self.board_shim.get_current_board_data(
            self.num_points_compute, BrainFlowPresets.DEFAULT_PRESET)[self.eeg_channels, :]
        eeg_data_plot = self.board_shim.get_current_board_data(
            self.num_points_plot, BrainFlowPresets.DEFAULT_PRESET)[self.eeg_channels, :]

        # collect gyro data
        gyro_data = self.board_shim.get_current_board_data(
            self.num_points_compute, BrainFlowPresets.AUXILIARY_PRESET)[self.gyro_channels, :]
        gyro_data_plot = self.board_shim.get_current_board_data(
            self.num_points_plot, BrainFlowPresets.AUXILIARY_PRESET)[self.gyro_channels, :]

        # collect ppg data
        # - please mind we are picking the first ppg channel only out of 3,
        #   which is channel 1 (zero-indexed) of the entire array.
        # - only plot data is required for PPG at current implementation
        ppg_data_plot = self.board_shim.get_current_board_data(
            self.num_points_plot, BrainFlowPresets.ANCILLARY_PRESET)[self.ppg_channels[0], :]

        # mean normalize
        eeg_data = eeg_data - np.mean(eeg_data, axis=0)
        eeg_data_plot = eeg_data_plot - np.mean(eeg_data_plot, axis=0)
        gyro_data = gyro_data - np.mean(gyro_data, axis=0)
        gyro_data_plot = gyro_data_plot - np.mean(gyro_data_plot, axis=0)
        # ppg_data = ppg_data - np.mean(ppg_data, axis=0)
        ppg_data_plot = ppg_data_plot - np.mean(ppg_data_plot, axis=0)

        #  power_metrics = [0,0,0,0]

        # add gyro data to curves, leave first few curves for eeg data.
        for count, _ in enumerate(self.gyro_channels):
            self.curves[len(self.eeg_channels) + count].setData(gyro_data_plot[count].tolist())
        head_movement = np.clip(np.mean(np.abs(gyro_data)) / 50, 0, 1)
        #  power_metrics[2] = head_movement

        # ppg: filter and add ppg to curves, again at the appropriate index.
        DataFilter.detrend(ppg_data_plot, DetrendOperations.CONSTANT.value)
        DataFilter.perform_bandpass(data=ppg_data_plot, sampling_rate=self.ppg_sampling_rate, start_freq=0.8,
                                    stop_freq=4.0, order=4, filter_type=FilterTypes.BUTTERWORTH.value, ripple=0.0)
        self.curves[eeg_data_plot.shape[0] + gyro_data_plot.shape[0]].setData(ppg_data_plot.tolist())

        # eeg processing
        avg_bands = [0, 0, 0, 0, 0]
        frontal_theta = 1
        parietal_alpha = 1
        engagement_idx = 1

        for count, _ in enumerate(self.eeg_channels):
            DataFilter.detrend(eeg_data[count], DetrendOperations.CONSTANT.value)
            DataFilter.perform_bandpass(data=eeg_data[count], sampling_rate=self.eeg_sampling_rate, start_freq=1.0,
                                        stop_freq=59.0, order=2, filter_type=FilterTypes.BUTTERWORTH.value, ripple=0.0)
            DataFilter.perform_bandstop(data=eeg_data[count], sampling_rate=self.eeg_sampling_rate, start_freq=48.0,
                                        stop_freq=52.0, order=2, filter_type=FilterTypes.BUTTERWORTH.value, ripple=0.0)
            # preprocess plot
            DataFilter.detrend(eeg_data_plot[count], DetrendOperations.CONSTANT.value)
            DataFilter.perform_bandpass(data=eeg_data_plot[count], sampling_rate=self.eeg_sampling_rate, start_freq=2.0,
                                        stop_freq=58.0, order=2, filter_type=FilterTypes.BUTTERWORTH.value, ripple=0.0)
            DataFilter.perform_bandstop(data=eeg_data_plot[count], sampling_rate=self.eeg_sampling_rate, start_freq=48.0,
                                        stop_freq=52.0, order=2, filter_type=FilterTypes.BUTTERWORTH.value, ripple=0.0)
            # plot timeseries
            self.curves[count].setData(eeg_data_plot[count].tolist())
            if len(eeg_data[count]) > self.psd_size:
                # compute psd
                psd_data = DataFilter.get_psd_welch(data=eeg_data[count], nfft=self.psd_size, overlap=self.psd_size // 2,
                                                    sampling_rate=self.eeg_sampling_rate, window=WindowOperations.BLACKMAN_HARRIS.value)
                lim = min(48, len(psd_data[0]))
                self.psd_curves[count].setData(psd_data[1][0:lim].tolist(), psd_data[0][0:lim].tolist())
                # compute bands
                delta = DataFilter.get_band_power(psd_data, 1.0, 4.0)
                theta = DataFilter.get_band_power(psd_data, 4.0, 8.0)
                alpha = DataFilter.get_band_power(psd_data, 8.0, 13.0)
                beta = DataFilter.get_band_power(psd_data, 13.0, 30.0)
                gamma = DataFilter.get_band_power(psd_data, 30.0, 60.0)
                avg_bands[0] = avg_bands[0] + delta
                avg_bands[1] = avg_bands[1] + theta
                avg_bands[2] = avg_bands[2] + alpha
                avg_bands[3] = avg_bands[3] + beta
                avg_bands[4] = avg_bands[4] + gamma

                # compute selfmade brain metrics
                engagement_idx += (beta / (theta + alpha)) / gamma

                if count == 1 or count == 4:
                    parietal_alpha += alpha / gamma
                else:
                    frontal_theta += theta / gamma

        avg_bands = [int(x / len(self.eeg_channels)) for x in avg_bands]  # average bands were just sums

        engagement_idx = engagement_idx / 4
        parietal_alpha = parietal_alpha / 2
        frontal_theta = frontal_theta / 2

        # engagement
        self.engagement_calib.append(engagement_idx)
        if len(self.engagement_calib) > self.calib_length:
            del self.engagement_calib[0]

        if len(self.engagement_hist) > self.hist_length:
            del self.engagement_hist[0]

        # scale
        engagement_z = (engagement_idx - np.mean(self.engagement_calib)) / np.std(self.engagement_calib)
        engagement_z /= 2 * self.brain_scale
        engagement_z += self.brain_center
        engagement_z = np.clip(engagement_z, 0.05, 1)
        self.engagement_hist.append(engagement_z)
        # print(engagement_z)
        # print(self.engagement_hist)

        # weighted mean
        engagement_weighted_mean = 0
        sumweight = 0
        for count, hist_val in enumerate(self.engagement_hist):
            engagement_weighted_mean += hist_val * count
            sumweight += count

        engagement_weighted_mean = engagement_weighted_mean / sumweight

        self.engagement = engagement_weighted_mean

        #   # inverse workload
        #   inverse_workload_idx = parietal_alpha/frontal_theta
        #   self.inverse_workload_calib.append(inverse_workload_idx)
        #   if len(self.inverse_workload_calib) > self.calib_length:
        #       del self.inverse_workload_calib[0]
        #
        #   if len(self.inverse_workload_hist) > self.hist_length:
        #       del self.inverse_workload_hist[0]
        #
        #  # print('mean: ' + str(np.mean(self.inverse_workload_calib)))
        #  # print('std: ' + str(np.std(self.inverse_workload_calib)))
        #
        #   # scale
        #   inverse_workload_z = (inverse_workload_idx - np.mean(self.inverse_workload_calib)) / np.std(self.inverse_workload_calib)
        #   inverse_workload_z /= 2*self.brain_scale
        #   inverse_workload_z += self.brain_center
        #   inverse_workload_z = np.clip(inverse_workload_z,0.05,1)
        #   self.inverse_workload_hist.append(inverse_workload_z)
        #
        #   # weighted mean
        #   inverse_workload_weighted_mean = 0
        #   sumweight = 0
        #   for count, hist_val in enumerate(self.inverse_workload_hist):
        #       inverse_workload_weighted_mean += hist_val*count
        #       sumweight += count
        #
        #   inverse_workload_weighted_mean = inverse_workload_weighted_mean / sumweight
        #
        #   self.inverse_workload = inverse_workload_weighted_mean

        self.power_metrics = np.float32(self.engagement + (1 - head_movement) * self.head_impact)

        # power_metrics[3] = self.inverse_workload

        # # ML brain metrics
        # bands = DataFilter.get_avg_band_powers(eeg_data_plot, self.eeg_channels, self.eeg_sampling_rate, True)
        # feature_vector = np.concatenate((bands[0], bands[1]))
        #
        # power_metrics[0] = self.concentration.predict(feature_vector)
        #  power_metrics[1] = self.relaxation.predict(feature_vector)

        # plot bars
        self.band_bar.setOpts(height=avg_bands)
        self.power_bar.setOpts(height=self.power_metrics)

        # print('###################')
        # print(self.power_metrics)
        # print('###################')

        self.outlet_transmit.push_sample([self.power_metrics])

        self.app.processEvents()


class ClassifierFactory:
    def __init__(self, type):
        self.type = type

    def __call__(self, *args, **kwargs):
        if self.type == 'LDA':
            return LDA(*args, **kwargs)
        elif self.type == 'SVM':
            return SVM(*args, **kwargs)
        else:
            raise ValueError("Type not known!")


class Classifier(ABC):
    def __init__(self, type, interval, filter, method):
        self.model = {}
        self.feature_list = []
        self.label_list = []
        self.type = type
        self.interval = interval
        self.filter = filter
        self.method = method

    @abstractmethod
    def train(self):
        raise NotImplementedError

    @abstractmethod
    def predict(self, board_shim, board_id, event_timestamp):
        raise NotImplementedError

    def collect_sample(self, board_shim, board_id, event_timestamp):
        interval = self.interval
        filter = self.filter
        method = self.method

        # fetch data
        [interval_start, interval_end] = interval.split(',')
        interval_start = int(interval_start.replace("[", ""))
        interval_end = int(interval_end.replace("]", ""))
        fs = board_shim.get_sampling_rate(board_id, BrainFlowPresets.DEFAULT_PRESET)
        num_sample = int(fs*(interval_end-interval_start + 100)/1000)
        chan_timestamp = board_shim.get_timestamp_channel(board_id, BrainFlowPresets.DEFAULT_PRESET)
        chan_eeg = board_shim.get_eeg_channels(board_id, BrainFlowPresets.DEFAULT_PRESET)
        # await asyncio.sleep(interval_end/1000 + 0.1)
        time.sleep(interval_end/1000 + 0.1)
        data = board_shim.get_current_board_data(num_sample, BrainFlowPresets.DEFAULT_PRESET).T
        # calculate the real interval based on timestamp of event
        interval_real = (data[:, chan_timestamp] - event_timestamp)*1000
        # print([interval_real[0], interval_real[-1]])

        # preprocessing for EEG data
        data_eeg = data[:, chan_eeg]
        # filtering for EEG data
        if filter == '':
            pass
        else:
            [low, high] = filter.split(',')
            low = float(low.replace("[", ""))
            high = float(high.replace("]", ""))
            # here use butterworth band-pass filter
            Wn = np.array([low, high]) / fs * 2
            b, a = sp.signal.butter(5, Wn, btype='bandpass')
            data_eeg = sp.signal.lfilter(b, a, data_eeg.T).T

        # re-reference EEG data
        eeg_mean = np.mean(data_eeg, axis=1, keepdims=True)
        data_eeg = np.hstack([data_eeg, np.zeros((data_eeg.shape[0], 1))])  # add a new channel full of zeros
        data_eeg = data_eeg - eeg_mean

        # use [, -200] to do baseline for EEG data
        idx_bl = (interval_real < -200)
        idx_post = np.logical_and(interval_real > 0, interval_real < interval_end)
        data_eeg = data_eeg[idx_post, :] - np.mean(data_eeg[idx_bl, :], axis=0)
        interval_real = interval_real[idx_post]

        # feature extracting
        if method == '':
            pass
        elif method == 'windowed-average-EEG':
            data_extract = data_eeg
            win_len = 50  # window length in ms
            n_win = int(interval_end / win_len)
            feature_vector = []
            for i in range(n_win):
                idx_in_win = np.logical_and(interval_real > win_len*i, interval_real < win_len*(i+1))
                feature_vector.append(np.mean(data_extract[idx_in_win, :], axis=0))
            feature_vector = np.concatenate(np.squeeze(feature_vector))
            return feature_vector
        elif method == 'windowed-average-EEG-motion':
            chan_motion = board_shim.get_accel_channels(board_id) + board_shim.get_gyro_channels(board_id)
            data = data[idx_post, :]
            data_motion = data[:, chan_motion]
            data_extract = np.concatenate((data_eeg, data_motion), axis=1)
            win_len = 50  # window length in ms
            n_win = int(interval_end / win_len)
            feature_vector = []
            for i in range(n_win):
                idx_in_win = np.logical_and(interval_real > win_len*i, interval_real < win_len*(i+1))
                feature_vector.append(np.mean(data_extract[idx_in_win, :], axis=0))
            feature_vector = np.concatenate(np.squeeze(feature_vector))
            return feature_vector
        else:
            print('wrong keyword for <method>!')


class LDA(Classifier):
    def __init__(self, type, interval, filter, method):
        super().__init__(type, interval, filter, method)
        self.feature_list = []
        self.label_list = []
        self.model = {}

    def train(self, cross_val=True, n_folds=5):
        feature_list = self.feature_list
        label_list = self.label_list
        if len(feature_list) < 5:
            print('only', len(feature_list), 'samples, please collect more!')
        else:
            self.model['parameter-w,b'] = self.train_LDA(feature_list, label_list)
            if cross_val is True:
                n_sample = len(feature_list)
                n_in_fold = np.floor(n_sample/n_folds).astype(int)
                n_sample = n_in_fold * n_folds
                perm = np.random.permutation(n_sample)
                acc_test = []

                # cross validation
                for i_fold in range(n_folds):
                    # train for each fold
                    idx_test = perm[i_fold * n_in_fold:(i_fold + 1) * n_in_fold]
                    idx_train = np.setdiff1d(range(n_sample), idx_test)
                    feature_list_train = np.array(feature_list)[idx_train].tolist()
                    label_list_train = np.array(label_list)[idx_train].tolist()
                    label_list_test = np.array(label_list)[idx_test].tolist()
                    w, b = self.train_LDA(feature_list_train, label_list_train)

                    # predict and calculate accuracy
                    prediction = w.T.dot(np.array(feature_list).T) - b
                    prediction_test = prediction[idx_test]
                    accuracy_test = (sum(prediction_test[np.array(label_list_test) == 0] < 0) + sum(
                        prediction_test[np.array(label_list_test) == 1] >= 0)) / len(prediction_test)
                    acc_test.append(accuracy_test)
                self.model['cross validation accuracy'] = np.mean(acc_test)
            else:
                self.model['cross validation accuracy'] = None

    def train_LDA(self, feature_list, label_list):
        X = np.array(feature_list).T  # features*samples
        y = np.array(label_list)
        mu1 = np.mean(X[:, y == 1], axis=1)
        mu0 = np.mean(X[:, y == 0], axis=1)
        # center features to estimate covariance
        Xpool = np.concatenate((X[:, y == 1] - mu1[:, np.newaxis], X[:, y == 0] - mu0[:, np.newaxis]), axis=1)
        C = np.cov(Xpool)
        w = np.linalg.pinv(C).dot(mu1 - mu0)
        b = w.T.dot((mu1 + mu0) / 2)
        return w, b

    def predict(self, board_shim, board_id, event_timestamp):
        if 'parameter-w,b' in self.model.keys():
            sample_to_predict = np.array(self.collect_sample(board_shim, board_id, event_timestamp)).T
            w, b = self.model['parameter-w,b']
            result = w.T.dot(sample_to_predict) - b
            print('prediction result:', result)
        else:
            print('no model trained yet, please train a model first!')


class SVM(Classifier):
    def __init__(self, type, interval, filter, method):
        super().__init__(type, interval, filter, method)
        self.feature_list = []
        self.label_list = []
        self.model = {}

    def train(self, cross_val=True, n_folds=5):
        feature_list = self.feature_list
        label_list = self.label_list
        if len(feature_list) < 5:
            print('only', len(feature_list), 'samples, please collect more!')
        else:
            X = np.array(feature_list)  # samples*features
            y = label_list
            clf = svm.SVC(probability=True)
            clf.fit(X, y)
            self.model['model'] = clf
            if cross_val is True:
                scores = cross_val_score(clf, X, y, cv=n_folds)
                self.model['cross validation accuracy'] = scores.mean()
            else:
                self.model['cross validation accuracy'] = None

    def predict(self, board_shim, board_id, event_timestamp):
        if 'model' in self.model.keys():
            sample_to_predict = np.array(self.collect_sample(board_shim, board_id, event_timestamp))
            clf = self.model['model']
            result = clf.predict([sample_to_predict])
            prob = clf.predict_proba([sample_to_predict])
            print('prediction result:', result, 'probability:', prob)
        else:
            print('no model trained yet, please train a model first!')


def message_decode(message, event_timestamp, dict_clf, board_shim, board_id):
    message_list = message.split(';')
    if message_list[0] == 'create':
        cf = ClassifierFactory(message_list[2])
        classifier = cf(message_list[2], message_list[3], message_list[4], message_list[5])
        dict_clf[message_list[1]] = classifier

    if message_list[0] == 'collect':
        clf_name = message_list[1]
        if clf_name not in dict_clf:
            print('no classifier named', clf_name, 'found, please create classifier first!')
        else:
            clf = dict_clf[clf_name]
            clf.feature_list.append(clf.collect_sample(board_shim, board_id, event_timestamp))
            clf.label_list.append(int(message_list[2]))
            print(np.array(clf.feature_list).shape, clf.label_list)

    if message_list[0] == 'train':
        clf_name = message_list[1]
        if clf_name not in dict_clf:
            print('no classifier named', clf_name, 'found, please create classifier first!')
        else:
            clf = dict_clf[clf_name]
            clf.train()

    if message_list[0] == 'predict':
        clf_name = message_list[1]
        if clf_name not in dict_clf:
            print('no classifier named', clf_name, 'found, please create classifier first!')
        else:
            clf = dict_clf[clf_name]
            clf.predict(board_shim, board_id, event_timestamp)

    if message_list[0] == 'dictionary':
        str_dict_info = ''
        for key, value in dict_clf.items():
            print(vars(value))
        #     str_clf_info = ''
        #     for k, v in vars(value).items():
        #         if not isinstance(v, str):
        #             if isinstance(v, dict):
        #                 v = json.dumps(v)
        #             else:
        #                 v = " ".join(map(str, v))
        #         str_clf_info = str_clf_info + k + ': ' + v + ', '
        #     str_dict_info = str_dict_info + key + ': ' + str_clf_info + ' ###### '
        # outlet.push_sample([str_dict_info])


def thread_event(board_shim, board_id):
    dict_clf = {}
    # create LSL stream to receive events
    streams = resolve_byprop("name", "SendMarkersOnClick")
    inlet = StreamInlet(streams[0])
    # create LSL stream to send information printed on console
    info = StreamInfo('SendPrintInfo', 'Markers', 1, 0, 'string', 'Zflow_SendPrintInfo')
    outlet = StreamOutlet(info)

    while True:
        event_sample, event_timestamp = inlet.pull_sample()
        diff = time.time() - local_clock()
        event_timestamp = event_timestamp+diff  # get timestamp with Unix Epoch format
        print("got %s at time %s" % (event_sample[0], event_timestamp))
        outlet.push_sample(["got %s at time %s" % (event_sample[0], event_timestamp)])
        message_decode(event_sample[0], event_timestamp, dict_clf, board_shim, board_id)


def start_all(board_id, params, streamparams, calib_length, power_length, scale, offset, head_impact):
    board_shim = BoardShim(board_id, params)
    board_shim.prepare_session()
    board_shim.config_board("p61")
    board_shim.start_stream(450000, streamparams)

    thread1 = threading.Thread(target=Graph, args=(board_shim, calib_length,
                               power_length, scale, offset, head_impact), daemon=True)
    thread1.start()
    thread2 = threading.Thread(target=thread_event, args=(board_shim, board_id), daemon=True)
    thread2.start()
    # asyncio.run(thread_event(board_shim, board_id))

    print(board_shim.get_board_descr(board_id))

    data_types = {
        'eeg': BrainFlowPresets.DEFAULT_PRESET,
        'gyro': BrainFlowPresets.AUXILIARY_PRESET,
        'ppg': BrainFlowPresets.ANCILLARY_PRESET,
    }
    outlets = {}

    for data_type, preset in data_types.items():
        n_chan = board_shim.get_num_rows(board_id, preset)
        rate = board_shim.get_sampling_rate(board_id, preset)
        info_data = StreamInfo('Z-flow-data', data_type, n_chan, rate, 'float32', 'zflow_SendData')
        info_data.desc().append_child_value("manufacturer", "Brainflow")
        info_data.desc().append_child_value("description", str(
            BoardShim.get_board_descr(board_id, preset)))
        outlets[data_type] = StreamOutlet(info_data)

    previous_timestamp = {'eeg': 0, 'gyro': 0, 'ppg': 0}
    diff = time.time() - local_clock()

    while True:
        for data_type, preset in data_types.items():
            timestamp_column = board_shim.get_timestamp_channel(board_id, preset=preset)

            # TODO: Potential cause for a bug here in the following lines
            # if (loop/thread) latency is longer then 1024/sample_rate we skip frames of data. This should be resolved.
            data = board_shim.get_current_board_data(1024, preset)
            # slice rows with timestamps bigger then previous_timestamp
            data = data[:, data[timestamp_column] > previous_timestamp[data_type]]

            # only update timestamp and push if there is something left to push.
            if data.shape[1] > 0:
                previous_timestamp[data_type] = data[timestamp_column, -1]
                outlets[data_type].push_chunk(data.tolist(), previous_timestamp[data_type]-diff)


def main():
    BoardShim.enable_dev_board_logger()
    # BoardShim.set_log_file('test_board.log')
    # logging.basicConfig(filename='example.log', level=logging.DEBUG)
    logging.basicConfig(filename='example.log', format='%(asctime)s %(levelname)-8s %(message)s', level=logging.DEBUG)
    # logging.basicConfig(level=logging.DEBUG)

    parser = argparse.ArgumentParser()
    # use docs to check which parameters are required for specific board, e.g. for Cyton - set serial port
    parser.add_argument('--timeout', type=int, help='timeout for device discovery or connection', required=False,
                        default=30)
    parser.add_argument('--ip-port', type=int, help='ip port', required=False, default=0)
    parser.add_argument('--ip-protocol', type=int, help='ip protocol, check IpProtocolType enum', required=False,
                        default=0)
    parser.add_argument('--ip-address', type=str, help='ip address', required=False, default='')
    parser.add_argument('--serial-port', type=str, help='serial port', required=False, default='')
    parser.add_argument('--mac-address', type=str, help='mac address', required=False, default='')
    parser.add_argument('--other-info', type=str, help='other info', required=False, default='')
    parser.add_argument('--streamer-params', type=str, help='streamer params', required=False, default='')
    parser.add_argument('--serial-number', type=str, help='serial number', required=False, default='')
    parser.add_argument('--board-id', type=int, help='board id, check docs to get a list of supported boards',
                        required=False, default=BoardIds.MUSE_S_BOARD)
    parser.add_argument('--file', type=str, help='file', required=False, default='')
    args = parser.parse_args()

    params = BrainFlowInputParams()
    params.ip_port = args.ip_port
    params.serial_port = args.serial_port
    params.mac_address = args.mac_address
    params.other_info = args.other_info
    params.serial_number = args.serial_number
    params.ip_address = args.ip_address
    params.ip_protocol = args.ip_protocol
    params.timeout = args.timeout
    params.file = args.file

    calib_length = 600
    power_length = 10
    scale = 1.5
    offset = 0.5
    head_impact = 0.2

    board_id = args.board_id
    streamparams = args.streamer_params

    start_all(board_id, params, streamparams, calib_length, power_length, scale, offset, head_impact)


def connect(board_id, timeout, calib_length, power_length, scale, offset, head_impact, record):
    BoardShim.enable_dev_board_logger()
    logging.basicConfig(level=logging.DEBUG)
    params = BrainFlowInputParams()
    params.timeout = timeout

    if record == 1:
        streamparams = "file://braindata.tsv:w"
    else:
        streamparams = ""

    start_all(board_id, params, streamparams, calib_length, power_length, scale, offset, head_impact)


if __name__ == '__main__':
    main()
